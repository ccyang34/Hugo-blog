
import requests
import pandas as pd
import numpy as np
from datetime import datetime
import pytz
import time
import os
import json
import json
import re
import akshare as ak
import matplotlib.pyplot as plt
import matplotlib
from pathlib import Path

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ŒGitHub Actions ä¼˜å…ˆä½¿ç”¨ Noto Sans CJK 
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'SimHei', 'Microsoft YaHei', 'PingFang SC', 'Arial Unicode MS', 'DejaVu Sans'] 
plt.rcParams['axes.unicode_minus'] = False


# ================= é…ç½®åŒºåŸŸ =================
# è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® DEEPSEEK_API_KEYï¼Œæˆ–ç›´æ¥åœ¨æ­¤å¤„å¡«å…¥ (ä¸æ¨èç›´æ¥æäº¤åˆ°ä»£ç åº“)
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-063857d175bd48038684520e7b6ec934")
DEEPSEEK_BASE_URL = "https://api.deepseek.com/v1"  # DeepSeek å®˜æ–¹ API åœ°å€



# Hugo åšå®¢é…ç½®
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
HUGO_BLOG_DIR = os.path.dirname(SCRIPT_DIR)
HUGO_CONTENT_DIR = os.path.join(HUGO_BLOG_DIR, "content", "posts")
HUGO_IMAGES_DIR = os.path.join(HUGO_BLOG_DIR, "static", "images", "charts")

ENABLE_HUGO_BLOG = True  # æ˜¯å¦å¯ç”¨Hugoåšå®¢ä¿å­˜åŠŸèƒ½
ENABLE_GIT_PUSH = os.getenv("ENABLE_GIT_PUSH", "false").lower() == "true"  # æ˜¯å¦å¯ç”¨Gitè‡ªåŠ¨æ¨é€
GIT_COMMIT_MESSAGE = os.getenv("GIT_COMMIT_MESSAGE", "AIå¸‚åœºåˆ†ææ—¥æŠ¥è‡ªåŠ¨æ›´æ–°")  # Gitæäº¤ä¿¡æ¯

# æ—¶åŒºé…ç½®
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    return datetime.now(BEIJING_TZ)

# ================= æ•°æ®è·å–ä¸å¤„ç† (å¤ç”¨ v2 æ ¸å¿ƒé€»è¾‘) =================

def fetch_data(retries=3, delay=2):
    url = 'https://sckd.dapanyuntu.com/api/api/industry_ma20_analysis_page?page=0'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Referer': 'https://sckd.dapanyuntu.com/'
    }
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"[Error] Fetching data: {e}, retrying...")
        time.sleep(delay)
    return None

def process_data(data):
    dates = data['dates']
    industries = data['industries']
    raw_data = data['data']
    parsed_data = []
    for point in raw_data:
        d_idx, i_idx, val = point
        if d_idx < len(dates) and i_idx < len(industries):
            parsed_data.append({'date': dates[d_idx], 'industry': industries[i_idx], 'value': val})
    df = pd.DataFrame(parsed_data)

    df = df.drop_duplicates(subset=['industry', 'date'])
    pivot = df.pivot(index='industry', columns='date', values='value')
    return pivot, dates

def calculate_breadth_momentum(pivot, dates):
    """
    è®¡ç®—å¸‚åœºå®½åº¦åŠ¨é‡ (3æ—¥/5æ—¥å˜åŒ–)
    """
    try:
        if len(dates) < 5:
            return None
            
        current = pivot[dates[-1]]
        prev_3d = pivot[dates[-3]]
        prev_5d = pivot[dates[-5]]
        
        momentum = pd.DataFrame({
            'Current': current,
            'Change3D': current - prev_3d,
            'Change5D': current - prev_5d
        })
        
        return momentum
    except Exception as e:
        print(f"[Warning] åŠ¨é‡è®¡ç®—å¤±è´¥: {e}")
        return None

def analyze_market_sentiment_snapshot():
    """
    åŸºäºå®æ—¶å¿«ç…§åˆ†æå¸‚åœºæƒ…ç»ª (æ¶¨è·Œæ¯”/æ¶¨åœæ•°/ä¸­ä½æ•°)
    """
    print("æ­£åœ¨åˆ†æå…¨å¸‚åœºå®æ—¶æƒ…ç»ª...")
    try:
        # è·å–å¿«ç…§ (å¸¦ç¼“å­˜)
        # æ³¨æ„: get_market_snapshot è¿”å›çš„æ˜¯ dict name map, è¿™é‡Œæˆ‘ä»¬éœ€è¦ raw dataframe
        # æ‰€ä»¥ç›´æ¥è°ƒç”¨ ak.stock_zh_a_spot() æˆ–å¤ç”¨é€»è¾‘
        df = ak.stock_zh_a_spot()
        
        if df is None or df.empty:
            return None
            
        # df columns: ä»£ç ,åç§°,æœ€æ–°ä»·,æ¶¨è·Œå¹…,æ¶¨è·Œé¢,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æœ€é«˜,æœ€ä½,ä»Šå¼€,æ˜¨æ”¶...
        # æ¶¨è·Œå¹… column might be 'æ¶¨è·Œå¹…' or 'changepercent' depending on source
        # Sina source: code, name, trade, pricechange, changepercent, buy, sell, settlement, open, high, low, volume, amount...
        
        # ç»Ÿä¸€åˆ—åæŸ¥æ‰¾
        pct_col = None
        for col in ['æ¶¨è·Œå¹…', 'changepercent', 'm:chg']:
            if col in df.columns:
                pct_col = col
                break
        
        if not pct_col:
            print("[Warning] æœªæ‰¾åˆ°æ¶¨è·Œå¹…åˆ—ï¼Œæ— æ³•åˆ†ææƒ…ç»ª")
            return None
            
        # æ¸…æ´—æ•°æ®
        df[pct_col] = pd.to_numeric(df[pct_col], errors='coerce').fillna(0)
        
        total_count = len(df)
        up_count = len(df[df[pct_col] > 0])
        down_count = len(df[df[pct_col] < 0])
        flat_count = len(df[df[pct_col] == 0])
        
        limit_up = len(df[df[pct_col] > 9.5])
        limit_down = len(df[df[pct_col] < -9.5])
        
        median_change = df[pct_col].median()
        mean_change = df[pct_col].mean()
        
        # æˆäº¤é¢ (å¦‚æœæœ‰)
        amount_col = None
        for col in ['æˆäº¤é¢', 'amount']:
            if col in df.columns:
                amount_col = col
                break
        
        total_amount = 0
        if amount_col:
             total_amount = pd.to_numeric(df[amount_col], errors='coerce').sum()
        
        sentiment = {
            'total': total_count,
            'up': up_count,
            'down': down_count,
            'flat': flat_count,
            'limit_up': limit_up,
            'limit_down': limit_down,
            'median_change': median_change,
            'mean_change': mean_change,
            'total_amount': total_amount
        }
        
        print(f"æƒ…ç»ªåˆ†æå®Œæˆ: æ¶¨{up_count}/è·Œ{down_count}, æ¶¨åœ{limit_up}")
        return sentiment
        
    except Exception as e:
        print(f"[Warning] æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
        return None

def get_sector_map():
    """
    è¡Œä¸šæ¿å—åˆ†ç±»æ˜ å°„è¡¨ (ä¼˜åŒ–ç‰ˆ)
    
    åˆ†ç±»é€»è¾‘ï¼š
    - ç§‘æŠ€æˆé•¿ï¼šæ”¿ç­–æ”¯æŒ+é«˜æˆé•¿+é«˜ä¼°å€¼
    - å¯é€‰æ¶ˆè´¹ï¼šç»æµngoodæ—¶è¡¨ç°å¼ºåŠ¿ï¼Œå—æ¶ˆè´¹èƒ½åŠ›å½±å“
    - å¿…é€‰æ¶ˆè´¹åŒ»è¯ï¼šé˜²å¾¡å±æ€§+åˆšéœ€ï¼Œç»æµä¸‹è¡Œä¸­ç›¸å¯¹æŠ—è·Œ
    - èƒ½æºèµ„æºï¼šå¤§å®—å•†å“+ä¼ ç»Ÿå‘¨æœŸï¼Œå—å•†å“ä»·æ ¼é©±åŠ¨
    - é«˜ç«¯åˆ¶é€ ï¼šæ–°èƒ½æº+æ™ºèƒ½åˆ¶é€ ï¼Œå—æ”¿ç­–æ‰¶æŒ+æŠ€æœ¯åˆ›æ–°é©±åŠ¨
    - ä¼ ç»Ÿåˆ¶é€ ï¼šä½ç«¯åˆ¶é€ +å»ºæï¼Œä¼ ç»Ÿå‘¨æœŸå±æ€§
    - å¤§é‡‘èï¼šé‡‘èå…¨æ¿å—
    - åŸºå»ºç‰©æµï¼šé€†å‘¨æœŸè°ƒèŠ‚+æ”¿ç­–å¯¹å†²
    - å…¬ç”¨äº‹ä¸šï¼šé˜²å¾¡+ç¨³å®šåˆ†çº¢
    - æˆ¿åœ°äº§é“¾ï¼šåœ°äº§åŠåå‘¨æœŸè¡Œä¸š
    - è´¸æ˜“ç»¼åˆï¼šéš¾ä»¥å½’ç±»çš„ç»¼åˆæ€§æ¿å—
    """
    return {
        # 1. ç§‘æŠ€æˆé•¿æ¿å—ï¼ˆæ”¿ç­–æ”¯æŒ+é«˜æˆé•¿+é«˜ä¼°å€¼ï¼‰
        'ç§‘æŠ€æˆé•¿': [
            # åŠå¯¼ä½“äº§ä¸šé“¾
            'åŠå¯¼ä½“', 'ç”µå­å…ƒä»¶', 'å…‰å­¦å…‰ç”µå­', 'ç”µå­åŒ–å­¦å“',
            # è®¡ç®—æœºä¸è½¯ä»¶
            'è®¡ç®—æœºè®¾å¤‡', 'è½¯ä»¶å¼€å‘', 'äº’è”ç½‘æœåŠ¡',
            # é€šä¿¡äº§ä¸šé“¾
            'é€šä¿¡è®¾å¤‡', 'é€šä¿¡æœåŠ¡',
            # æ–°å…´ç§‘æŠ€
            'æ¶ˆè´¹ç”µå­'  # ä¿ç•™åœ¨ç§‘æŠ€æˆé•¿ä¸­ï¼Œæ›´ç¬¦åˆäº§ä¸šå±æ€§
        ],
        
        # 2. å¯é€‰æ¶ˆè´¹ï¼ˆç»æµngoodæ—¶è¡¨ç°å¼ºåŠ¿ï¼‰
        'å¯é€‰æ¶ˆè´¹': [
            # é«˜ç«¯æ¶ˆè´¹
            'é…¿é…’è¡Œä¸š', 
            # è€ç”¨æ¶ˆè´¹å“
            'å®¶ç”µè¡Œä¸š', 'ç å®é¦–é¥°',
            # æ±½è½¦äº§ä¸šé“¾
            'æ±½è½¦æ•´è½¦', 'æ±½è½¦é›¶éƒ¨ä»¶', 'æ±½è½¦æœåŠ¡',
            # ä¼‘é—²æœåŠ¡
            'æ—…æ¸¸é…’åº—', 'å•†ä¸šç™¾è´§', 'çººç»‡æœè£…', 'æ–‡åŒ–ä¼ åª’', 'æ•™è‚²',
            # å®¶å±…ç›¸å…³ï¼ˆåœ°äº§åå‘¨æœŸï¼‰
            'è£…ä¿®å»ºæ', 'è£…ä¿®è£…é¥°', 'å®¶ç”¨è½»å·¥'
        ],
        
        # 3. å¿…é€‰æ¶ˆè´¹+åŒ»è¯ï¼ˆé˜²å¾¡å±æ€§+åˆšéœ€ï¼‰
        'å¿…é€‰æ¶ˆè´¹åŒ»è¯': [
            # åŒ»è¯å…¨äº§ä¸šé“¾
            'åŒ»è¯å•†ä¸š', 'ä¸­è¯', 'åŒ–å­¦åˆ¶è¯', 'ç”Ÿç‰©åˆ¶å“', 'åŒ»ç–—å™¨æ¢°', 'åŒ»ç–—æœåŠ¡', 'ç¾å®¹æŠ¤ç†',
            # å†œä¸š
            'å†œç‰§é¥²æ¸”',
            # åŸºç¡€æ¶ˆè´¹ï¼ˆä¸é«˜ç«¯é…’ç±»åŒºåˆ†ï¼‰
            'é£Ÿå“é¥®æ–™'  
        ],
        
        # 4. èƒ½æºèµ„æºï¼ˆå¤§å®—å•†å“+ä¼ ç»Ÿå‘¨æœŸï¼‰
        'èƒ½æºèµ„æº': [
            # èƒ½æº
            'ç…¤ç‚­è¡Œä¸š', 'çŸ³æ²¹è¡Œä¸š', 'é‡‡æ˜è¡Œä¸š',
            # é‡‘å±
            'é’¢é“è¡Œä¸š', 'æœ‰è‰²é‡‘å±', 'è´µé‡‘å±', 'å°é‡‘å±', 'èƒ½æºé‡‘å±',
            # åŸºç¡€ææ–™
            'åŒ–å­¦åŸæ–™', 'åŒ–å­¦åˆ¶å“', 'åŒ–çº¤è¡Œä¸š', 'éé‡‘å±ææ–™'
        ],
        
        # 5. é«˜ç«¯åˆ¶é€ ï¼ˆæ–°èƒ½æº+æ™ºèƒ½åˆ¶é€ ï¼‰
        'é«˜ç«¯åˆ¶é€ ': [
            # æ–°èƒ½æºäº§ä¸šé“¾
            'å…‰ä¼è®¾å¤‡', 'é£ç”µè®¾å¤‡', 'ç”µæ± ', 'ç”µæœº', 'ç”µæºè®¾å¤‡', 'ç”µç½‘è®¾å¤‡',
            # é«˜ç«¯è£…å¤‡
            'ä¸“ç”¨è®¾å¤‡', 'é€šç”¨è®¾å¤‡',
            # èˆªç©ºèˆªå¤©
            'èˆªå¤©èˆªç©º',
            # äº¤è¿è£…å¤‡
            'äº¤è¿è®¾å¤‡', 'èˆ¹èˆ¶åˆ¶é€ ',
            # ç²¾å¯†åˆ¶é€ ï¼ˆç§‘æŠ€å±æ€§å¼ºï¼‰
            'ä»ªå™¨ä»ªè¡¨'
        ],
        
        # 6. ä¼ ç»Ÿåˆ¶é€ ï¼ˆä½ç«¯åˆ¶é€ +å»ºæï¼‰
        'ä¼ ç»Ÿåˆ¶é€ ': [
            # å»ºæå»ºç­‘
            'æ°´æ³¥å»ºæ', 
            # ä¼ ç»Ÿåˆ¶é€ 
            'å¡‘æ–™åˆ¶å“', 'æ©¡èƒ¶åˆ¶å“', 'ç»ç’ƒç»çº¤', 'é€ çº¸å°åˆ·', 'åŒ…è£…ææ–™',
            # åŒ–å·¥ç›¸å…³
            'åŒ–è‚¥è¡Œä¸š', 'å†œè¯å…½è¯'
        ],
        
        # 7. å¤§é‡‘èï¼ˆé‡‘èå…¨æ¿å—ï¼‰
        'å¤§é‡‘è': [
            'é“¶è¡Œ', 'è¯åˆ¸', 'ä¿é™©', 'å¤šå…ƒé‡‘è'
        ],
        
        # 8. åŸºå»ºç‰©æµï¼ˆé€†å‘¨æœŸ+æ”¿ç­–å¯¹å†²ï¼‰
        'åŸºå»ºç‰©æµ': [
            # äº¤é€šè¿è¾“
            'é“è·¯å…¬è·¯', 'èˆªè¿æ¸¯å£', 'ç‰©æµè¡Œä¸š', 'èˆªç©ºæœºåœº',
            # åŸºå»ºå·¥ç¨‹
            'å·¥ç¨‹å»ºè®¾', 'å·¥ç¨‹å’¨è¯¢æœåŠ¡', 'å·¥ç¨‹æœºæ¢°',
            # ä¸“ä¸šæœåŠ¡
            'ä¸“ä¸šæœåŠ¡'
        ],
        
        # 9. å…¬ç”¨äº‹ä¸šï¼ˆé˜²å¾¡+ç¨³å®šåˆ†çº¢ï¼‰
        'å…¬ç”¨äº‹ä¸š': [
            'å…¬ç”¨äº‹ä¸š', 'ç”µåŠ›è¡Œä¸š', 'ç‡ƒæ°”', 'ç¯ä¿è¡Œä¸š'
        ],
        
        # 10. æˆ¿åœ°äº§é“¾ï¼ˆç‹¬ç«‹æ¿å—ï¼‰
        'æˆ¿åœ°äº§é“¾': [
            # åœ°äº§å¼€å‘
            'æˆ¿åœ°äº§å¼€å‘', 'æˆ¿åœ°äº§æœåŠ¡'
        ],
        
        # 11. è´¸æ˜“ç»¼åˆï¼ˆéš¾ä»¥å½’ç±»çš„æ¿å—ï¼‰
        'è´¸æ˜“ç»¼åˆ': [
            'è´¸æ˜“è¡Œä¸š', 'ç»¼åˆè¡Œä¸š',
            # å¨±ä¹ç›¸å…³ï¼ˆéš¾ä»¥å½’ç±»ï¼‰
            'æ¸¸æˆ'  
        ]
    }

# ================= æœ¬åœ°é¢„åˆ†æ (ä¸º AI å‡†å¤‡æ•°æ®) =================


def prepare_context_for_ai(pivot, dates, momentum_df=None, sentiment_data=None):
    latest_date = dates[-1]
    
    # --- 1. å…¨å¸‚åœºåˆ†å¸ƒç»Ÿè®¡ (Market Distribution) ---
    current_vals = pivot[latest_date]
    total_inds = len(current_vals)
    overheated = (current_vals > 80).sum()
    oversold = (current_vals < 20).sum()
    neutral = total_inds - overheated - oversold
    median_breadth = current_vals.median()
    avg_breadth = current_vals.mean()
    
    # --- 2. æ„å»ºå®Œæ•´å†å²æ•°æ®çŸ©é˜µ (Full History) ---
    # ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ—¥æœŸï¼Œä¸è¿›è¡Œæˆªæ–­
    full_dates = dates
    
    sector_map = get_sector_map()
    ind_to_sector = {}
    for sec, inds in sector_map.items():
        for ind in inds:
            ind_to_sector[ind] = sec
            
    # æ„å»º CSV å¤´: è¡Œä¸š,æ¿å—,æ—¥æœŸ1,æ—¥æœŸ2...
    history_csv_lines = [f"è¡Œä¸šåç§°,æ‰€å±æ¿å—,{','.join(full_dates)}"]
    
    # æŒ‰æœ€æ–°å®½åº¦é™åºæ’åˆ—
    sorted_inds = current_vals.sort_values(ascending=False).index
    
    for ind in sorted_inds:
        sector = ind_to_sector.get(ind, "å…¶ä»–")
        # è·å–è¯¥è¡Œä¸šåœ¨æ‰€æœ‰æ—¥æœŸçš„å€¼åºåˆ—
        vals = pivot.loc[ind, full_dates]
        # æ ¼å¼åŒ–æ•°å€¼ï¼Œä¿ç•™1ä½å°æ•°
        vals_str = ",".join([f"{v:.1f}" if pd.notnull(v) else "" for v in vals])
        history_csv_lines.append(f"{ind},{sector},{vals_str}")
    
    full_history_str = "\n".join(history_csv_lines)

    # --- 3. è¡¥å……åŠ¨é‡ä¸æƒ…ç»ªæ•°æ® ---
    momentum_str = ""
    if momentum_df is not None:
        # æ‰¾å‡ºåŠ¨é‡æœ€å¼º(Change5D Max)å’ŒåŠ¨é‡æœ€å¼±(Change5D Min)çš„å‰5å
        top_momentum = momentum_df.sort_values('Change5D', ascending=False).head(5)
        bottom_momentum = momentum_df.sort_values('Change5D', ascending=True).head(5)
        
        momentum_str = "\n[è¡Œä¸šåŠ¨é‡å¼‚åŠ¨ (5æ—¥å®½åº¦å˜åŒ–)]\n"
        momentum_str += "åŠ é€Ÿå‘ä¸Š (Leaders):\n"
        for idx, row in top_momentum.iterrows():
            momentum_str += f"- {idx}: å½“å‰{row['Current']:.1f}%, 5æ—¥å˜åŠ¨+{row['Change5D']:.1f}%\n"
            
        momentum_str += "åŠ é€Ÿå‘ä¸‹ (Laggards):\n"
        for idx, row in bottom_momentum.iterrows():
            momentum_str += f"- {idx}: å½“å‰{row['Current']:.1f}%, 5æ—¥å˜åŠ¨{row['Change5D']:.1f}%\n"

    sentiment_str = ""
    if sentiment_data:
        sentiment_str = f"""
    [å…¨å¸‚åœºå®æ—¶æƒ…ç»ªå¿«ç…§]
    - ä¸Šæ¶¨å®¶æ•°: {sentiment_data['up']} / ä¸‹è·Œå®¶æ•°: {sentiment_data['down']}
    - æ¶¨åœå®¶æ•°: {sentiment_data['limit_up']} / è·Œåœå®¶æ•°: {sentiment_data['limit_down']}
    - æ¶¨è·Œå¹…ä¸­ä½æ•°: {sentiment_data['median_change']:.2f}%
    - æ€»æˆäº¤é¢: {sentiment_data['total_amount']/100000000:.1f} äº¿
        """

    # --- 4. æ„å»ºå‘é€ç»™ AI çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡ ---
    context = f"""
    [åˆ†æåŸºå‡†]
    æ•°æ®æˆªæ­¢æ—¥æœŸ: {latest_date}
    åŒ…å«å†å²å¤©æ•°: {len(full_dates)} å¤©

    [å¸‚åœºå…¨æ™¯ç»Ÿè®¡]
    - å…¨å¸‚åœºå¹³å‡å®½åº¦: {avg_breadth:.1f}%
    - å®½åº¦ä¸­ä½æ•°: {median_breadth:.1f}%
    - æåº¦è¿‡çƒ­(>80%)è¡Œä¸šæ•°: {overheated} / {total_inds}
    - æåº¦å†°ç‚¹(<20%)è¡Œä¸šæ•°: {oversold} / {total_inds}
    - æ­£å¸¸åŒºé—´(20-80%)è¡Œä¸šæ•°: {neutral} / {total_inds}

    {sentiment_str}

    {momentum_str}

    [å…¨è¡Œä¸šå®Œæ•´å†å²æ•°æ® (CSVçŸ©é˜µ)]
    {full_history_str}
    """
    return context

# ================= AI åˆ†ææ¨¡å— (DeepSeek) =================


def call_deepseek_analysis(context):
    if not DEEPSEEK_API_KEY or "sk-" not in DEEPSEEK_API_KEY:
        print("[Warning] æœªé…ç½® DEEPSEEK_API_KEYï¼Œè·³è¿‡ AI åˆ†æã€‚")
        return "æœªé…ç½® API Keyï¼Œæ— æ³•ç”Ÿæˆ AI æŠ¥å‘Šã€‚"

    system_prompt = """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰20å¹´ç»éªŒçš„Aè‚¡é¦–å¸­ç­–ç•¥åˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„å…¨å¸‚åœºè¡Œä¸šå®½åº¦æ•°æ®ï¼ˆMarket Breadthï¼‰ã€åŠ¨é‡å¼‚åŠ¨æ•°æ®å’Œå®æ—¶å¸‚åœºæƒ…ç»ªå¿«ç…§ï¼Œæ’°å†™ä¸€ä»½æ·±åº¦å¸‚åœºåˆ†ææŠ¥å‘Šã€‚

    **åˆ†æé€»è¾‘ä¸è¦æ±‚ï¼š**

    1.  **å…¨æ™¯å®šè°ƒ (The Big Picture)**:
        *   ç»“åˆâ€œå®æ—¶æƒ…ç»ªå¿«ç…§â€ï¼ˆæ¶¨è·Œæ¯”ã€æ¶¨åœæ•°ã€ä¸­ä½æ•°ï¼‰åˆ¤æ–­å½“æ—¥ç›˜é¢å¼ºå¼±ã€‚
        *   ç»“åˆâ€œè¿‡çƒ­/å†°ç‚¹â€è¡Œä¸šåˆ†å¸ƒï¼Œåˆ¤æ–­å¸‚åœºæ˜¯å¦å¤„äºæç«¯ä½ç½®ã€‚
        *   **å…³é”®åˆ¤æ–­**: å¸‚åœºæ˜¯åœ¨åŠ é€Ÿä¸Šè¡Œã€é«˜ä½åˆ†æ­§ã€è¿˜æ˜¯åº•éƒ¨åå¼¹ï¼Ÿ

    2.  **ç»“æ„ä¸ä¸»çº¿ (Structure & Rotation)**:
        *   åˆ©ç”¨**[è¡Œä¸šåŠ¨é‡å¼‚åŠ¨]**æ•°æ®ï¼Œè¯†åˆ«â€œåŠ é€Ÿå‘ä¸Šâ€çš„æ¿å—ã€‚è¿™äº›æ˜¯å½“å‰çš„ä¸»çº¿ã€‚
        *   å¯¹æ¯”â€œå½“å‰å®½åº¦â€é«˜ä½†â€œ5æ—¥å˜åŠ¨â€ä¸ºè´Ÿçš„æ¿å—ï¼Œè­¦æƒ•é«˜ä½é€€æ½®ã€‚
        *   **æ·±åº¦æŒ–æ˜**: æ‰¾å‡ºâ€œå¼ºä¸­ä¹‹å¼ºâ€ï¼ˆé¢†æ¶¨è¡Œä¸šï¼‰å’Œâ€œå¼±ä¸­ä¹‹å¼ºâ€ï¼ˆåº•éƒ¨åˆšå¯åŠ¨ï¼‰ã€‚
        
    3.  **å¼‚åŠ¨ä¸èƒŒç¦» (Divergence)**:
        *   å¯»æ‰¾â€œèƒŒç¦»â€ç°è±¡ï¼šä¾‹å¦‚æŸäº›é«˜ä½æ¿å—è™½ç„¶å®½åº¦ä»é«˜ï¼Œä½†å‘¨å˜åŒ–å¼€å§‹è½¬è´Ÿï¼ˆé«˜ä½æ´¾å‘è¿¹è±¡ï¼‰ã€‚
        *   å¯»æ‰¾â€œå¹¿åº¦æ¨åŠ›â€ï¼šæ˜¯å¦æœ‰å¤§é‡è¡Œä¸šåœ¨çŸ­æ—¶é—´å†…åŒæ—¶å¤§å¹…ä¸Šæ¶¨ï¼Ÿ

    4.  **å®æˆ˜ç­–ç•¥ (Actionable Strategy)**:
        *   ç»™å‡ºå…·ä½“çš„ä»“ä½å»ºè®®ï¼ˆ0-10æˆï¼‰ã€‚
        *   **è¿›æ”»æ–¹å‘**: å…·ä½“åˆ°ç»†åˆ†è¡Œä¸šï¼Œä¼˜å…ˆé€‰æ‹©åŠ¨é‡åŠ é€Ÿå‘ä¸Šçš„æ¿å—ã€‚
        *   **é˜²å¾¡/è§„é¿**: ç‚¹åéœ€è¦å›é¿çš„é£é™©æ¿å—ï¼ˆé«˜ä½åŠ¨èƒ½è¡°ç«­ï¼‰ã€‚

    **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
    *   ä½¿ç”¨ Markdown æ ¼å¼ã€‚
    *   **å¿…é¡»å¼•ç”¨æ•°æ®**: åœ¨åˆ†ææ—¶ï¼Œå¿…é¡»å¼•ç”¨å…·ä½“çš„å®½åº¦æ•°å€¼ã€5æ—¥å˜åŒ–ç‡æˆ–æƒ…ç»ªæŒ‡æ ‡ï¼ˆæ¶¨åœæ•°ç­‰ï¼‰ä½œä¸ºæ”¯æ’‘ã€‚
    *   è¯­æ°”ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›ã€‚ä¸è¦ä½¿ç”¨æ¨¡æ£±ä¸¤å¯çš„åºŸè¯ã€‚
    *   å­—æ•°æ§åˆ¶åœ¨ 800-1000 å­—ä¹‹é—´ï¼Œå†…å®¹è¦è¯¦å®ã€‚

    **æŠ¥å‘Šç»“æ„ï¼š**
    # æ·±åº¦å¸‚åœºå®½åº¦æ—¥æŠ¥
    ## ğŸ“Š å¸‚åœºå…¨æ™¯ä¸æƒ…ç»ª
    ## ğŸš€ è¡Œä¸šåŠ¨é‡ä¸ä¸»çº¿æ‰«æ
    ## âš ï¸ å¼‚åŠ¨èƒŒç¦»ä¸é£é™©
    ## ğŸ’¡ äº¤æ˜“ç­–ç•¥ä¸å»ºè®®
    
    **é‡è¦ï¼š** è¯·åœ¨æŠ¥å‘Šçš„æœ€åï¼Œ**å¿…é¡»**ä»¥ JSON æ ¼å¼åˆ—å‡ºä½ æœ€çœ‹å¥½çš„ 1-2 ä¸ªå…·ä½“çš„â€œè¿›æ”»æ–¹å‘â€æ¿å—åç§°ï¼Œå¹¶ä¸ºæ¯ä¸ªæ¿å—æ¨è 5 åªæœ€å…·ä»£è¡¨æ€§çš„é¾™å¤´è‚¡/å¼ºåŠ¿è‚¡ä»£ç ï¼ˆ6ä½æ•°å­—ä»£ç ï¼‰ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
    ```json
    {
        "recommendations": [
            {"sector": "åŠå¯¼ä½“", "stocks": ["688981", "603501", "002371", "600584", "002156"]},
            {"sector": "é…¿é…’è¡Œä¸š", "stocks": ["600519", "000858", "000568", "600809", "000596"]}
        ]
    }
    ```
    ï¼ˆè¯·ç¡®ä¿ JSON æ ¼å¼æ ‡å‡†ï¼Œsector ä¸è¾“å…¥åç§°ä¸€è‡´ï¼Œstocks ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
    """

    user_prompt = f"è¿™æ˜¯æœ€æ–°çš„å…¨å¸‚åœºè¡Œä¸šå®½åº¦æ•°æ®ï¼Œè¯·å¼€å§‹åˆ†æï¼š\n{context}"

    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.5, # é™ä½æ¸©åº¦ä»¥å¢åŠ åˆ†æçš„ä¸¥è°¨æ€§
        "max_tokens": 2000
    }

    try:
        response = requests.post(
            f"{DEEPSEEK_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"},
            json=payload,
            timeout=60 # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºç”Ÿæˆå†…å®¹å˜é•¿äº†
        )
        if response.status_code == 200:
            content = response.json()['choices'][0]['message']['content']
            return content
        else:
            return f"AI è¯·æ±‚å¤±è´¥: {response.text}"
    except Exception as e:
        return f"AI è¯·æ±‚å¼‚å¸¸: {e}"

# ================= ä¸ªè‚¡æ·±åº¦åˆ†ææ¨¡å— (Round 2) =================

def extract_recommended_sectors(ai_content):
    """
    ä»ç¬¬ä¸€è½® AI å›å¤ä¸­æå–æ¨èæ¿å—åŠä¸ªè‚¡ JSON
    è¿”å›æ•°æ®ç»“æ„: [{'sector': 'xx', 'stocks': ['code', ...]}, ...]
    """
    try:
        # å°è¯•åŒ¹é… ```json ... ``` ä»£ç å—
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
            data = json.loads(json_str)
            return data.get("recommendations", [])
        
        # å¤‡ç”¨ï¼šå°è¯•ç›´æ¥æœç´¢ JSON ç»“æ„ (looking for "recommendations")
        json_match = re.search(r'(\{.*"recommendations".*\})', ai_content, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
            data = json.loads(json_str)
            return data.get("recommendations", [])
            
        print("[Warning] æœªèƒ½åœ¨ AI å›å¤ä¸­æ‰¾åˆ°æ¨èæ¿å— JSONã€‚")
        return []
    except Exception as e:
        print(f"[Error] è§£ææ¨èæ¿å— JSON å¤±è´¥: {e}")
        return []


# ================= å…¨å±€ç¼“å­˜ =================
MARKET_SNAPSHOT = None

def get_market_snapshot():
    """
    è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…å¿«ç…§ (å¸¦ç¼“å­˜) - ç”¨äºæŸ¥æ‰¾è‚¡ç¥¨åç§°ç­‰åŸºç¡€ä¿¡æ¯
    ä½¿ç”¨ Sina æ¥å£ (ak.stock_zh_a_spot)
    """
    global MARKET_SNAPSHOT
    if MARKET_SNAPSHOT is not None:
        return MARKET_SNAPSHOT
        
    print("æ­£åœ¨è·å–å…¨å¸‚åœºå¿«ç…§ (Sina) ä»¥åŒ¹é…è‚¡ç¥¨åç§°...")
    try:
        # ak.stock_zh_a_spot() è¿”å›æ‰€æœ‰Aè‚¡å®æ—¶è¡Œæƒ…ï¼ŒåŒ…å«ä»£ç ã€åç§°
        df = ak.stock_zh_a_spot()
        if df is not None and not df.empty:
            # å»ºç«‹ ä»£ç  -> åç§° çš„å­—å…¸ï¼Œæ–¹ä¾¿æŸ¥è¯¢
            # Sina è¿”å›çš„ä»£ç é€šå¸¸æ˜¯ sz000xxx æˆ– 600xxx (ä¸å¸¦å‰ç¼€? éœ€æ£€æŸ¥test output)
            # Test output: "bj920000", "bj920001". 
            # Output from `test_combined_fix` showed "ä»£ç " column has prefixes!
            
            # æˆ‘ä»¬åªéœ€è¦åšä¸€ä¸ª map: code (without prefix if possible, or handle both) -> name
            # å­˜ä¸º dict
            snapshot = {}
            for _, row in df.iterrows():
                full_code = str(row['ä»£ç ']) 
                name = str(row['åç§°'])
                # å…¼å®¹å¸¦å‰ç¼€å’Œä¸å¸¦å‰ç¼€
                # æ¯”å¦‚ bj920000 -> 920000
                # sh600519 -> 600519
                # sz000001 -> 000001
                
                # Strip 2 char prefix if it is letters
                clean_code = full_code
                if len(full_code) > 2 and not full_code[0].isdigit():
                     clean_code = full_code[2:]
                
                snapshot[full_code] = name
                snapshot[clean_code] = name
                
            MARKET_SNAPSHOT = snapshot
            print(f"å…¨å¸‚åœºå¿«ç…§è·å–æˆåŠŸï¼Œå…± {len(df)} åªè‚¡ç¥¨ã€‚")
            return MARKET_SNAPSHOT
    except Exception as e:
        print(f"[Warning] è·å–å…¨å¸‚åœºå¿«ç…§å¤±è´¥: {e}")
    
    return {}

def fetch_sector_stocks(recommendations):
    """
    è·å–æ¨èæ¿å—çš„â€œå¼ºåŠ¿åŠ›â€é¾™å¤´è‚¡ (v3 å¢å¼ºç‰ˆ)
    é€»è¾‘ï¼šä½¿ç”¨ AI æ¨èçš„ä¸ªè‚¡åˆ—è¡¨ï¼Œä¸å†ä¾èµ– Akshare æ¿å—æˆåˆ†è‚¡æ¥å£ (å› ç½‘ç»œ/æ¥å£ä¸ç¨³å®š/ç¼ºå¤±)ã€‚
    """
    stock_map = {}
    print(f"æ­£åœ¨å‡†å¤‡ AI æ¨èçš„æ¿å—ä¸ªè‚¡æ•°æ®...")
    
    # è·å–å¿«ç…§ä»¥ä¾¿æŸ¥æ‰¾åç§°
    snapshot = get_market_snapshot()
    
    for item in recommendations:
        sector = item.get('sector')
        stock_codes = item.get('stocks', [])
        
        if not sector or not stock_codes:
            continue
            
        print(f"  - æ­£åœ¨æŸ¥è¯¢ [{sector}] æ¨èä¸ªè‚¡: {stock_codes}")
        
        stocks_info = []
        for code in stock_codes:
            # ç®€å•æ¸…ç†ä»£ç 
            code = str(code).strip()
            
            # æŸ¥æ‰¾åç§°
            name = snapshot.get(code, f"Code:{code}")
            
            stocks_info.append({
                'code': code,
                'name': name,
                'pe': 0, # æ•°æ®æºç¼ºå¤±ï¼Œæš‚ç½®0
                'pb': 0
            })
            
        stock_map[sector] = stocks_info
            
    return stock_map

def calculate_technical_indicators(df):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: MA, RSI, ATR
    """
    try:
        # MA
        df['MA5'] = df['æ”¶ç›˜'].rolling(window=5).mean()
        df['MA20'] = df['æ”¶ç›˜'].rolling(window=20).mean()
        df['MA60'] = df['æ”¶ç›˜'].rolling(window=60).mean()
        
        # RSI (14)
        delta = df['æ”¶ç›˜'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # ATR (14)
        # TR = Max(High-Low, Abs(High-PreClose), Abs(Low-PreClose))
        df['PreClose'] = df['æ”¶ç›˜'].shift(1)
        df['H-L'] = df['æœ€é«˜'] - df['æœ€ä½']
        df['H-PC'] = abs(df['æœ€é«˜'] - df['PreClose'])
        df['L-PC'] = abs(df['æœ€ä½'] - df['PreClose'])
        df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)
        df['ATR'] = df['TR'].rolling(window=14).mean()
        
        return df
    except Exception as e:
        print(f"    [Warning] æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return df

def get_sina_symbol(code):
    """
    è½¬æ¢ä»£ç ä¸º Sina æ ¼å¼ (sh600000, sz000001)
    """
    if code.startswith('6'):
        return f"sh{code}"
    elif code.startswith('0') or code.startswith('3'):
        return f"sz{code}"
    elif code.startswith('4') or code.startswith('8'):
        return f"bj{code}" 
    else:
        return code

def fetch_one_stock_history_robust(code, start_date, end_date):
    """
    è·å–ä¸ªè‚¡å†å²æ•°æ® (ä¼˜å…ˆ Sinaï¼Œå¤±è´¥åˆ™é™çº§ä¸º Eastmoney)
    è¿”å›æ ‡å‡†åŒ– DataFrame: columns=[æ—¥æœŸ, å¼€ç›˜, æ”¶ç›˜, æœ€é«˜, æœ€ä½, æˆäº¤é‡, æ¶¨è·Œå¹…, æ¢æ‰‹ç‡]
    """
    # 1. å°è¯• Sina æ¥å£ (ak.stock_zh_a_daily)
    try:
        sina_symbol = get_sina_symbol(code)
        # Sina æ¥å£æ— éœ€ start_date/end_date è¿‡æ»¤ï¼Œå®ƒé»˜è®¤è¿”å›å†å²æ‰€æœ‰æˆ–è¿‘æœŸæ•°æ®
        # adjust='qfq' å‰å¤æƒ
        df = ak.stock_zh_a_daily(symbol=sina_symbol, adjust="qfq")
        
        if df is not None and not df.empty:
            # Sina è¿”å›åˆ—åé€šå¸¸ä¸ºè‹±æ–‡: date, open, high, low, close, volume, outstanding_share, turnover
            # éœ€è¦é‡å‘½åä¸ºä¸­æ–‡ä»¥å…¼å®¹åç»­é€»è¾‘
            rename_map = {
                'date': 'æ—¥æœŸ',
                'open': 'å¼€ç›˜',
                'close': 'æ”¶ç›˜',
                'high': 'æœ€é«˜',
                'low': 'æœ€ä½',
                'volume': 'æˆäº¤é‡',
                'turnover': 'æ¢æ‰‹ç‡' # æ³¨æ„ï¼šSina è¿”å›çš„ turnover å¯èƒ½æ˜¯å°æ•° (0.01) ä¹Ÿå¯èƒ½æ˜¯ç™¾åˆ†æ¯”ï¼Œéœ€æ£€æŸ¥
            }
            df = df.rename(columns=rename_map)
            
            # æ‰‹åŠ¨è¿‡æ»¤æ—¥æœŸ
            # è½¬æ¢ start_date, end_date (string "YYYYMMDD") åˆ° datetime æˆ– string "YYYY-MM-DD" comparison
            start_dt = pd.to_datetime(start_date, format='%Y%m%d')
            end_dt = pd.to_datetime(end_date, format='%Y%m%d')
            
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']) # ç¡®ä¿æ˜¯ datetime
            df = df[(df['æ—¥æœŸ'] >= start_dt) & (df['æ—¥æœŸ'] <= end_dt)].copy()
            
            if not df.empty:
                # è¡¥å……è®¡ç®— 'æ¶¨è·Œå¹…' (pct_chg)
                df = df.sort_values(by='æ—¥æœŸ')
                df['æ¶¨è·Œå¹…'] = df['æ”¶ç›˜'].pct_change() * 100
                df['æ¶¨è·Œå¹…'] = df['æ¶¨è·Œå¹…'].fillna(0)
                
                # æ ¼å¼åŒ–æ—¥æœŸä¸ºå­—ç¬¦ä¸² YYYY-MM-DD
                df['æ—¥æœŸ'] = df['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
                
                # ç¡®ä¿ 'æ¢æ‰‹ç‡' å­˜åœ¨ (å¦‚æœ Sina æ²¡è¿”å›)
                if 'æ¢æ‰‹ç‡' not in df.columns:
                     df['æ¢æ‰‹ç‡'] = 0.0
                     
                return df, "Sina"
    except Exception as e:
        # print(f"    [Debug] Sina æ¥å£è·å– {code} å¤±è´¥: {e}ï¼Œå°è¯• Eastmoney...")
        pass

    # 2. å¤±è´¥ fallback: Eastmoney (ak.stock_zh_a_hist)
    try:
        df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_date, end_date=end_date, adjust="qfq")
        if df is not None and not df.empty:
            return df, "Eastmoney"
    except Exception as e:
        print(f"    [Error] Eastmoney æ¥å£è·å– {code} äº¦å¤±è´¥: {e}")
        
    return None, None

def fetch_stock_history(stock_map):
    """
    è·å–ä¸ªè‚¡ 60 å¤©å†å²æ•°æ® (v3: å¢åŠ åŸºæœ¬é¢å’ŒæŠ€æœ¯æŒ‡æ ‡ä¸Šä¸‹æ–‡)
    """
    context_parts = []
    
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - pd.Timedelta(days=120)).strftime("%Y%m%d") #ä»¥æ­¤ç¡®ä¿æœ‰è¶³å¤Ÿçš„çª—å£è®¡ç®—MA60
    
    for sector, stocks in stock_map.items():
        if not stocks:
            continue
            
        sector_context = f"### æ¿å—ï¼š{sector}\n"
        
        for stock in stocks:
            code = stock['code']
            name = stock['name']
            pe = stock['pe']
            pb = stock['pb']
            
            print(f"  - è·å–ä¸ªè‚¡å†å²æ•°æ®: {name} ({code})...")
            
            # å¢åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    # ä½¿ç”¨å°è£…çš„ Robust å‡½æ•° (Sina -> EM)
                    df, source = fetch_one_stock_history_robust(code, start_date, end_date)
                    
                    if df is not None and not df.empty:
                        # print(f"    (æ•°æ®æ¥æº: {source})") 
                        
                        # è®¡ç®—æŒ‡æ ‡
                        df = calculate_technical_indicators(df)
                        
                        # å–æœ€å 60 è¡Œç”¨äºå±•ç¤º
                        df_display = df.tail(60)
                        
                        if df_display.empty:
                            print(f"    [Warning] {name} æ•°æ®åœ¨è¿‡æ»¤åä¸ºç©ºã€‚")
                            break

                        latest = df_display.iloc[-1]
                        
                        # æ„å»ºå¢å¼ºç‰ˆä¸Šä¸‹æ–‡
                        stock_str = f"#### {name} ({code})\n"
                        stock_str += f"- **åŸºæœ¬é¢**: PE(åŠ¨æ€)={pe}, PB={pb}\n"
                        stock_str += f"- **æœ€æ–°æŒ‡æ ‡**: MA5={latest['MA5']:.2f}, MA20={latest['MA20']:.2f}, MA60={latest['MA60']:.2f}, RSI(14)={latest['RSI']:.1f}, ATR(14)={latest['ATR']:.2f}\n"
                        stock_str += "æ—¥æœŸ,æ”¶ç›˜,æ¶¨è·Œå¹…,æ¢æ‰‹ç‡\n"
                        
                        for _, row in df_display.iterrows():
                            # å…¼å®¹å¯èƒ½å­˜åœ¨çš„åˆ—åé—®é¢˜
                            date_str = str(row['æ—¥æœŸ'])
                            close_val = row['æ”¶ç›˜']
                            pct_chg = row.get('æ¶¨è·Œå¹…', 0)
                            turnover = row.get('æ¢æ‰‹ç‡', 0)
                            
                            stock_str += f"{date_str},{close_val},{pct_chg:.2f},{turnover}\n"
                        
                        sector_context += stock_str + "\n"
                        break # æˆåŠŸåˆ™è·³å‡ºé‡è¯•
                    else:
                        raise Exception("Fetching returned None or Empty")
                        
                except Exception as e:
                    print(f"    [Warning] è·å– {name} å†å²æ•°æ®å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")
                    time.sleep(2) # å¤±è´¥ç­‰å¾…
        
        context_parts.append(sector_context)
        
    return "\n".join(context_parts)

def call_deepseek_stock_review(stock_context):
    """
    ç¬¬äºŒè½® AIï¼šä¸ªè‚¡æ·±åº¦è¯„ä¼° (v3 å¢å¼ºç‰ˆ)
    """
    if not stock_context:
        return ""
        
    print(f"[{get_beijing_time().strftime('%H:%M:%S')}] æ­£åœ¨è¯·æ±‚ DeepSeek è¿›è¡Œä¸ªè‚¡æ·±åº¦è¯„ä¼° (v3 Round 2)...")
    
    system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é‡åŒ–äº¤æ˜“å‘˜ã€‚æ ¹æ®æä¾›çš„é‡ç‚¹æ¿å—åŠå…¶å®åŠ›ä¸ªè‚¡çš„æ•°æ®ï¼ˆå«åŸºæœ¬é¢PE/PBå’ŒæŠ€æœ¯æŒ‡æ ‡MA/RSI/ATRï¼‰ï¼Œè¯·ç»™å‡ºä¸“ä¸šã€çŠ€åˆ©çš„çŸ­çº¿ç‚¹è¯„ã€‚
    
    **åˆ†æè¦æ±‚ï¼š**
    1.  **åŸºæœ¬é¢æ‰«æ**ï¼šç»“åˆPE/PBï¼Œå¿«é€Ÿåˆ¤æ–­ä¼°å€¼å®‰å…¨æ€§ï¼ˆè¿‡é«˜éœ€è­¦æƒ•ï¼Œè¿‡ä½æœ‰å®‰å…¨å«ï¼‰ã€‚
    2.  **æŠ€æœ¯é¢å…±æŒ¯**ï¼š
        *   åˆ©ç”¨ **MA (å‡çº¿)** åˆ¤æ–­è¶‹åŠ¿ï¼ˆå¤šå¤´æ’åˆ—/ç©ºå¤´æ’åˆ—/çº ç¼ ï¼‰ã€‚
        *   åˆ©ç”¨ **RSI** åˆ¤æ–­æƒ…ç»ªï¼ˆ>70è¶…ä¹°éœ€è­¦æƒ•å›è°ƒï¼Œ<30è¶…å–å¯èƒ½æœ‰åå¼¹ï¼‰ã€‚
    3.  **äº¤æ˜“å»ºè®® (å¸¦é£æ§)**ï¼š
        *   **è¯„çº§**ï¼šã€ç§¯æä¹°å…¥ã€‘ã€ã€é€¢ä½å…³æ³¨ã€‘ã€ã€æŒæœ‰è§‚å¯Ÿã€‘æˆ–ã€å–å‡º/è§„é¿ã€‘ã€‚
        *   **æ­¢æŸä½è®¡ç®—**ï¼šè¯·å‚è€ƒ **ATR (å¹³å‡çœŸå®æ³¢å¹…)** æŒ‡æ ‡ç»™å‡ºç§‘å­¦çš„æ­¢æŸä½å»ºè®®ã€‚é€šå¸¸æ­¢æŸä½ = å½“å‰ä»· - (2 * ATR)ã€‚è¯·è®¡ç®—å‡ºå…·ä½“æ•°å€¼ã€‚
        *   **ä½å¸åŒºé—´**ï¼šç»“åˆ MA20 æˆ– MA5 ç»™å‡ºæ”¯æ’‘ä½ã€‚
        
    **è¾“å‡ºæ ¼å¼ï¼š**
    ## ğŸš€ æ ¸å¿ƒæœºä¼šä¸ªè‚¡ç²¾è¯„ (v3 æ™ºèƒ½å¢å¼ºç‰ˆ)
    
    ### [æ¿å—åç§°]
    #### [æ’å] [è‚¡ç¥¨åç§°] (ä»£ç )
    *   **ä¼°å€¼ä¸è¶‹åŠ¿**: PE [...], è¶‹åŠ¿å¤„äº [...] (åŸºäºå‡çº¿)ã€‚
    *   **æŒ‡æ ‡ä¿¡å·**: RSI ä¸º [...], æ˜¾ç¤º [...]ã€‚
    *   **äº¤æ˜“å»ºè®®**: ã€...ã€‘
        *   ğŸ¯ **ä½å¸åŒºé—´**: ...
        *   ğŸ›¡ï¸ **ATRæ­¢æŸ**: ... (å»ºè®®è®¾åœ¨ xxx å…ƒ)
    
    (ä¿æŒå†…å®¹ç²¾ç‚¼ï¼Œæ•°æ®è¯´è¯ã€‚)
    """
    
    user_prompt = f"ä»¥ä¸‹æ˜¯åŸºäºæ™ºèƒ½ç­–ç•¥ï¼ˆå¤§å¸‚å€¼+å¼ºåŠ¨é‡ï¼‰é€‰å‡ºçš„æ¨èæ¿å—é¾™å¤´è‚¡æ•°æ®ï¼Œè¯·è¿›è¡Œè¯„ä¼°ï¼š\n\n{stock_context}"
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.4, # é™ä½æ¸©åº¦ï¼Œè¦æ±‚æ›´ä¸¥è°¨çš„è®¡ç®—
        "max_tokens": 1500
    }
    
    try:
        response = requests.post(
            f"{DEEPSEEK_BASE_URL}/chat/completions",
            headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}", "Content-Type": "application/json"},
            json=payload,
            timeout=60
        )
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return f"AI ä¸ªè‚¡åˆ†æè¯·æ±‚å¤±è´¥: {response.text}"
    except Exception as e:
        return f"AI ä¸ªè‚¡åˆ†æè¯·æ±‚å¼‚å¸¸: {e}"

# ================= å¯è§†åŒ–æ¨¡å— =================

def plot_market_breadth(pivot, dates):
    """
    ç»˜åˆ¶å¸‚åœºå®½åº¦å…¨æ™¯å›¾
    """
    try:
        print("æ­£åœ¨ç”Ÿæˆå¸‚åœºå®½åº¦å…¨æ™¯å›¾...")
        latest_date = dates[-1]
        current_vals = pivot[latest_date].sort_values(ascending=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ŒGitHub Actions ä¼˜å…ˆä½¿ç”¨ Noto Sans CJK
        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'SimHei', 'Microsoft YaHei', 'PingFang SC', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºç”»å¸ƒ
        plt.figure(figsize=(10, 15)) # é«˜ä¸€ç‚¹ï¼Œå› ä¸ºè¡Œä¸šå¾ˆå¤š
        
        # é¢œè‰²æ˜ å°„
        colors = []
        for val in current_vals:
            if val >= 80:
                colors.append('#ff4d4f') # çº¢è‰² è¿‡çƒ­
            elif val <= 20:
                colors.append('#1890ff') # è“è‰² å†°ç‚¹
            else:
                colors.append('#8c8c8c') # ç°è‰² æ­£å¸¸
        
        # ç»˜åˆ¶æ¡å½¢å›¾
        bars = plt.barh(current_vals.index, current_vals.values, color=colors, height=0.6)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            width = bar.get_width()
            plt.text(width + 1, bar.get_y() + bar.get_height()/2, 
                     f'{width:.1f}', va='center', fontsize=9)
            
        plt.title(f'Aè‚¡å…¨å¸‚åœºè¡Œä¸šå®½åº¦æ’è¡Œ ({latest_date})', fontsize=16, pad=20)
        plt.xlabel('MA20ä¸Šæ–¹ä¸ªè‚¡å æ¯” (%)', fontsize=12)
        plt.xlim(0, 105) # ç•™å‡ºæ ‡ç­¾ç©ºé—´
        plt.grid(axis='x', linestyle='--', alpha=0.3)
        
        # æ·»åŠ å‚è€ƒçº¿
        plt.axvline(x=20, color='#1890ff', linestyle='--', alpha=0.5)
        plt.axvline(x=80, color='#ff4d4f', linestyle='--', alpha=0.5)
        
        plt.tight_layout()
        
        # ä¿å­˜è·¯å¾„
        # å›¾ç‰‡ä¿å­˜åˆ° static/images/charts/
        static_img_dir = HUGO_IMAGES_DIR
        
        if not os.path.exists(static_img_dir):
            os.makedirs(static_img_dir, exist_ok=True)
            
        # å›ºå®šæ–‡ä»¶å
        filename = "Aè‚¡å¸‚åœºå®½åº¦å…¨æ™¯å›¾.png"
        save_path = os.path.join(static_img_dir, filename)
        
        plt.savefig(save_path, dpi=120, bbox_inches='tight')
        plt.close()
        
        print(f"[Info] å¸‚åœºå®½åº¦å…¨æ™¯å›¾å·²ç”Ÿæˆ: {save_path}")
        

        # è¿”å›ç”¨äº Markdown å¼•ç”¨çš„ç›¸å¯¹è·¯å¾„
        return f"/images/charts/{filename}"
        
    except Exception as e:
        print(f"[Error] ç»˜å›¾å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def plot_sector_momentum(momentum_df, date_str):
    """
    ç»˜åˆ¶è¡Œä¸šåŠ¨é‡æ•£ç‚¹å›¾ (X: å½“å‰å®½åº¦, Y: 5æ—¥å˜åŒ–)
    """
    try:
        if momentum_df is None:
            return None
            
        print("æ­£åœ¨ç”Ÿæˆè¡Œä¸šåŠ¨é‡æ•£ç‚¹å›¾...")
        
        plt.figure(figsize=(12, 10))
        
        x = momentum_df['Current']
        y = momentum_df['Change5D']
        
        # ç»˜åˆ¶æ•£ç‚¹
        # æ ¹æ®è±¡é™è®¾ç½®é¢œè‰²
        colors = []
        for idx, row in momentum_df.iterrows():
            curr = row['Current']
            chg = row['Change5D']
            if curr > 50 and chg > 0:
                colors.append('#ff4d4f') # å¼º+å¼º (çº¢)
            elif curr > 50 and chg < 0:
                colors.append('#faad14') # å¼º+å¼± (é»„)
            elif curr < 50 and chg > 0:
                colors.append('#1890ff') # å¼±+å¼º (è“)
            else:
                colors.append('#8c8c8c') # å¼±+å¼± (ç°)
                
        plt.scatter(x, y, c=colors, alpha=0.7, s=100)
        
        # æ·»åŠ æ ‡ç­¾ (åªæ ‡è®°æå€¼ç‚¹ä»¥é¿å…æ‹¥æŒ¤)
        # é€»è¾‘: è·ç¦»ä¸­å¿ƒç‚¹ (50, 0) æœ€è¿œçš„ N ä¸ªç‚¹ï¼Œæˆ–è€…æ¯ä¸ªè±¡é™é€‰å‡ ä¸ª
        for idx, row in momentum_df.iterrows():
            curr = row['Current']
            chg = row['Change5D']
            
            # ç®€å•çš„è¿‡æ»¤é€»è¾‘ï¼šåªæ˜¾ç¤ºç‰¹åˆ«æ˜¾è‘—çš„
            if abs(chg) > 10 or curr > 85 or curr < 15:
                plt.text(curr+1, chg, idx, fontsize=9, alpha=0.8)
        
        plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)
        plt.axvline(x=50, color='black', linestyle='--', alpha=0.3)
        
        plt.title(f'è¡Œä¸šå®½åº¦åŠ¨é‡åˆ†æ (5æ—¥å˜åŒ– vs å½“å‰æ°´å¹³) - {date_str}', fontsize=16)
        plt.xlabel('å½“å‰å¸‚åœºå®½åº¦ (MA20%)', fontsize=12)
        plt.ylabel('5æ—¥å®½åº¦å˜åŒ– (%)', fontsize=12)
        
        # æ·»åŠ è±¡é™è¯´æ˜
        plt.text(95, 15, 'é¢†æ¶¨/ä¸»çº¿\n(å¼ºåŠ¿åŠ é€Ÿ)', ha='right', va='top', fontsize=12, color='#ff4d4f', fontweight='bold')
        plt.text(95, -15, 'é«˜ä½æ»æ¶¨\n(åŠ¨èƒ½è¡°ç«­)', ha='right', va='bottom', fontsize=12, color='#faad14', fontweight='bold')
        plt.text(5, 15, 'åº•éƒ¨åè½¬\n(è“„åŠ¿å¾…å‘)', ha='left', va='top', fontsize=12, color='#1890ff', fontweight='bold')
        plt.text(5, -15, 'ä½ä½å¼±åŠ¿\n(ç»§ç»­æ¢åº•)', ha='left', va='bottom', fontsize=12, color='#8c8c8c', fontweight='bold')
        
        plt.grid(True, linestyle=':', alpha=0.6)
        plt.tight_layout()
        
        # ä¿å­˜
        static_img_dir = HUGO_IMAGES_DIR
        if not os.path.exists(static_img_dir):
            os.makedirs(static_img_dir, exist_ok=True)
            
        filename = "Aè‚¡è¡Œä¸šåŠ¨é‡åˆ†æå›¾.png"
        save_path = os.path.join(static_img_dir, filename)
        
        plt.savefig(save_path, dpi=120, bbox_inches='tight')
        plt.close()
        
        print(f"[Info] è¡Œä¸šåŠ¨é‡å›¾å·²ç”Ÿæˆ: {save_path}")
        return f"/images/charts/{filename}"
        
    except Exception as e:
        print(f"[Error] åŠ¨é‡å›¾ç»˜åˆ¶å¤±è´¥: {e}")
        return None

# ================= Hugoåšå®¢é›†æˆæ¨¡å— =================


def save_to_hugo_blog(content, beijing_time, image_path=None, extra_images=None):
    """
    ä¿å­˜æŠ¥å‘Šåˆ°Hugoåšå®¢ï¼Œå¹¶æ”¯æŒGitè‡ªåŠ¨æ¨é€
    extra_images: list of tuples (title, path)
    """
    # æ„å»ºHugoåšå®¢æ–‡ä»¶è·¯å¾„
    
    # æ£€æŸ¥Hugoåšå®¢è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(HUGO_BLOG_DIR):
        print(f"[Warning] Hugoåšå®¢è·¯å¾„ä¸å­˜åœ¨: {HUGO_BLOG_DIR}")
        return False
        
    if not os.path.exists(HUGO_CONTENT_DIR):
        print(f"[Warning] Hugoå†…å®¹ç›®å½•ä¸å­˜åœ¨: {HUGO_CONTENT_DIR}")
        return False
    
    # æ„å»ºæ–‡ä»¶å (å›ºå®šä¸­æ–‡æ–‡ä»¶åï¼Œä¸å¸¦æ—¥æœŸ)
    date_str = beijing_time.strftime('%Y-%m-%d')
    hugo_filename = "Aè‚¡å¸‚åœºå®½åº¦åˆ†ææ—¥æŠ¥.md"
    hugo_file_path = os.path.join(HUGO_CONTENT_DIR, hugo_filename)
    
    featured_image = image_path if image_path else ""
    
    # ç»Ÿä¸€å›ºå®šæ ‡é¢˜
    fixed_title = "ğŸ“ˆAè‚¡å¸‚åœºå®½åº¦åˆ†ææ—¥æŠ¥"
    date_iso = beijing_time.strftime('%Y-%m-%dT%H:%M:%S+08:00')
    
    # æ„å»ºHugo Front Matter
    front_matter = f"""---
title: "{fixed_title}"
date: {date_iso}
lastmod: {date_iso}
description: "åŸºäºå¸‚åœºå®½åº¦æŒ‡æ ‡çš„Aè‚¡æ·±åº¦åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«AIæ™ºèƒ½è§£è¯»å’ŒæŠ•èµ„å»ºè®®"
tags: ["Aè‚¡", "å¸‚åœºåˆ†æ", "AIåˆ†æ", "æŠ•èµ„ç­–ç•¥", "è‚¡ç¥¨å¸‚åœº"]
categories: ["å¸‚åœºåˆ†æ", "æŠ•èµ„ç­–ç•¥"]
author: ["AIåˆ†æå¸ˆ"]
image: "{featured_image}"
draft: false
---

"""
    
    # æ’å…¥å›¾ç‰‡ (å¦‚æœæœ‰)
    image_section = ""
    if image_path:
        image_section += f"## ğŸ“Š å¸‚åœºå®½åº¦å…¨æ™¯å›¾\n\n![Aè‚¡å¸‚åœºå®½åº¦å…¨æ™¯å›¾]({image_path})\n\n"
    
    if extra_images:
        for title, path in extra_images:
            image_section += f"## {title}\n\n![{title}]({path})\n\n"

    # ç»„åˆå®Œæ•´å†…å®¹
    full_content = front_matter + image_section + content
    
    try:
        # ä¿å­˜åˆ°Hugoåšå®¢ç›®å½•
        with open(hugo_file_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        print(f"[Info] æŠ¥å‘Šå·²ä¿å­˜åˆ°Hugoåšå®¢: {hugo_file_path}")
        
        # å¦‚æœå¯ç”¨Gitæ¨é€
        if ENABLE_GIT_PUSH:
            push_to_git(HUGO_BLOG_DIR, hugo_filename)
        
        return True
        
    except Exception as e:
        print(f"[Error] ä¿å­˜åˆ°Hugoåšå®¢å¤±è´¥: {e}")
        return False

def push_to_git(hugo_blog_path, filename):
    """
    æ¨é€åˆ°Gitä»“åº“ (GitHubç¯å¢ƒä¼˜åŒ–ç‰ˆ)
    """
    try:
        import subprocess
        
        # åˆ‡æ¢åˆ°Hugoåšå®¢ç›®å½•
        original_cwd = os.getcwd()
        os.chdir(hugo_blog_path)
        
        # Gitæ·»åŠ æ–°æ–‡ä»¶
        new_file_path = os.path.join(HUGO_CONTENT_DIR, filename)
        subprocess.run(['git', 'add', new_file_path], check=True, capture_output=True)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´éœ€è¦æäº¤
        result = subprocess.run(['git', 'status', '--porcelain'], check=True, capture_output=True, text=True)
        if result.stdout.strip():
            # æœ‰å˜æ›´ï¼Œæ‰§è¡Œæäº¤
            subprocess.run(['git', 'commit', '-m', GIT_COMMIT_MESSAGE], check=True, capture_output=True)
            
            # å°è¯•æ¨é€åˆ°mainåˆ†æ”¯ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•masteråˆ†æ”¯
            try:
                subprocess.run(['git', 'push', 'origin', 'main'], check=True, capture_output=True)
                print("[Info] Gitæ¨é€æˆåŠŸ (mainåˆ†æ”¯)")
            except subprocess.CalledProcessError:
                try:
                    subprocess.run(['git', 'push', 'origin', 'master'], check=True, capture_output=True)
                    print("[Info] Gitæ¨é€æˆåŠŸ (masteråˆ†æ”¯)")
                except subprocess.CalledProcessError as e:
                    print(f"[Warning] Gitæ¨é€åˆ°masteråˆ†æ”¯ä¹Ÿå¤±è´¥: {e}")
        else:
            print("[Info] æ²¡æœ‰å˜æ›´éœ€è¦æäº¤å’Œæ¨é€")
        
        # æ¢å¤åŸå§‹å·¥ä½œç›®å½•
        os.chdir(original_cwd)
        
    except subprocess.CalledProcessError as e:
        print(f"[Warning] Gitæ“ä½œå¤±è´¥: {e}")
        # å°è¯•æ¢å¤å·¥ä½œç›®å½•
        try:
            os.chdir(original_cwd)
        except:
            pass
    except Exception as e:
        print(f"[Warning] Gitæ¨é€å¼‚å¸¸: {e}")
        # å°è¯•æ¢å¤å·¥ä½œç›®å½•
        try:
            os.chdir(original_cwd)
        except:
            pass

# ================= ä¸»ç¨‹åº =================

def main():
    beijing_time = get_beijing_time()
    print(f"[{beijing_time.strftime('%H:%M:%S')}] å¼€å§‹æ‰§è¡Œå¸‚åœºåˆ†æä»»åŠ¡...")
    
    # 1. è·å–æ•°æ®
    data = fetch_data()
    if not data:
        print("[Error] æ•°æ®è·å–å¤±è´¥ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚")
        return

    # 2. å¤„ç†æ•°æ®
    pivot, dates = process_data(data)
    
    # æ£€æŸ¥æœ€æ–°æ•°æ®æ—¥æœŸæ˜¯å¦ä¸ºä»Šå¤©
    latest_date = dates[-1]
    today_date = beijing_time.strftime('%Y-%m-%d')
    
    # [DEV MODE] v3 æµ‹è¯•é˜¶æ®µï¼Œå¦‚æœæ˜¯å‘¨æœ«ï¼Œå…è®¸è·‘æ˜¨å¤©çš„æœ€æ–°æ•°æ®ï¼Œä»…ç»™ Warning ä¸ return
    if latest_date != today_date:
        print(f"[Warning] æ•°æ®æœ€æ–°æ—¥æœŸ ({latest_date}) ä¸ç­‰äºä»Šå¤© ({today_date})ã€‚")
        # return # v3 æš‚æ—¶æ³¨é‡Šæ‰ï¼Œå…è®¸å›æµ‹æ¼”ç¤º
    

    # 3. ç”Ÿæˆæ•°æ®ä¸Šä¸‹æ–‡
    # è®¡ç®—åŠ¨é‡
    momentum_df = calculate_breadth_momentum(pivot, dates)
    
    # è·å–å®æ—¶æƒ…ç»ª
    sentiment_data = analyze_market_sentiment_snapshot()
    
    context = prepare_context_for_ai(pivot, dates, momentum_df, sentiment_data)
    print("--- ç”Ÿæˆçš„æ•°æ®ä¸Šä¸‹æ–‡ ---")
    print(context)
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    image_rel_path = plot_market_breadth(pivot, dates)
    
    extra_images = []
    # ç”ŸæˆåŠ¨é‡å›¾
    momentum_img_path = plot_sector_momentum(momentum_df, dates[-1])
    if momentum_img_path:
        extra_images.append(("ğŸš€ è¡Œä¸šåŠ¨é‡åˆ†æå›¾", momentum_img_path))
    
    # 4. è°ƒç”¨ AI åˆ†æ (Round 1: å¸‚åœºå®½åº¦)
    print(f"[{get_beijing_time().strftime('%H:%M:%S')}] æ­£åœ¨è¯·æ±‚ DeepSeek è¿›è¡Œåˆ†æ (Round 1)...")
    ai_report_round1 = call_deepseek_analysis(context)
    
    # --- Round 2: æ¨èæ¿å—ä¸ªè‚¡æŒ–æ˜ ---
    ai_report_round2 = ""
    
    # 1. æå–æ¨èæ¿å—
    recommended_sectors = extract_recommended_sectors(ai_report_round1)
    
    if recommended_sectors:
        print(f"--- æ•è·æ¨èæ¿å—: {recommended_sectors} ---")
        
        # 2. è·å–é¾™å¤´è‚¡æ•°æ®
        stock_map = fetch_sector_stocks(recommended_sectors)
        
        if stock_map:
            # 3. è·å–å†å²è¡Œæƒ…ä¸Šä¸‹æ–‡
            stock_context = fetch_stock_history(stock_map)
            
            # 4. è°ƒç”¨ AI åˆ†æ (Round 2)
            if stock_context:
                ai_report_round2 = call_deepseek_stock_review(stock_context)
            else:
                print("[Warning] æœªèƒ½æ„å»ºæœ‰æ•ˆçš„ä¸ªè‚¡å†å²æ•°æ®ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡ Round 2ã€‚")
        else:
            print("[Warning] æœªèƒ½è·å–ä»»ä½•æ¿å—æˆåˆ†è‚¡ï¼Œè·³è¿‡ Round 2ã€‚")
    else:
        print("[Info] ç¬¬ä¸€è½®æŠ¥å‘Šæœªæ˜ç¡®æ¨èæ¿å—æˆ–è§£æå¤±è´¥ï¼Œè·³è¿‡ Round 2 ä¸ªè‚¡åˆ†æã€‚")


    # 5. ç»„åˆæœ€ç»ˆæŠ¥å‘Š
    beijing_time = get_beijing_time()
    report_header = f"""
> **æ¨é€æ—¶é—´**: {beijing_time.strftime('%Y-%m-%d %H:%M')} (åŒ—äº¬æ—¶é—´) | æ¯ä¸ªäº¤æ˜“æ—¥ä¸‹åˆ 15:30 æ¨é€
> **æœ€æ–°æ•°æ®æ—¥æœŸ**: {latest_date}
> **å¸‚åœºå®½åº¦å®šä¹‰**: å¸‚åœºå®½åº¦ï¼ˆMarket Breadthï¼‰æ˜¯æŒ‡å½“å‰å¤„äº 20 æ—¥å‡çº¿ï¼ˆMA20ï¼‰ä¹‹ä¸Šçš„è‚¡ç¥¨å æ¯”ã€‚å®½åº¦è¶Šé«˜ï¼Œè¯´æ˜å¸‚åœºå‚ä¸åº¦è¶Šå¹¿ï¼Œèµšé’±æ•ˆåº”è¶Šå¼ºï¼›åä¹‹åˆ™è¡¨æ˜å¸‚åœºæƒ…ç»ªä½è¿·ï¼Œä»…å°‘æ•°ä¸ªè‚¡æ´»è·ƒã€‚
> - **< 20%**: æåº¦å†°ç‚¹ï¼Œå¾€å¾€æ˜¯åº•éƒ¨åŒºåŸŸ
> - **20-80%**: æ­£å¸¸éœ‡è¡åŒºé—´
> - **> 80%**: æåº¦è¿‡çƒ­ï¼Œå¾€å¾€æ˜¯é¡¶éƒ¨åŒºåŸŸ

---
"""
    
    final_report = report_header + ai_report_round1 + "\n\n" + ai_report_round2 + f"""

---
*æ•°æ®æ¥æº: å¤§ç›˜äº‘å›¾ | AI åˆ†æ: DeepSeek*
    """
    
    # 6. ä¿å­˜ä¸æ¨é€
    # ä¿å­˜åˆ°å½“å‰ç›®å½•ï¼ˆä½œä¸ºå¤‡ä»½ï¼‰
    filename = "Aè‚¡å¸‚åœºå®½åº¦åˆ†ææ—¥æŠ¥.md"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(final_report)
    print(f"[Info] æŠ¥å‘Šå·²ä¿å­˜è‡³ {filename}")
    

    # å¦‚æœå¯ç”¨Hugoåšå®¢ä¿å­˜åŠŸèƒ½
    if ENABLE_HUGO_BLOG:
        print("[Info] æ­£åœ¨ä¿å­˜åˆ°Hugoåšå®¢...")
        hugo_success = save_to_hugo_blog(final_report, beijing_time, image_rel_path, extra_images)
        if not hugo_success:
            print("[Warning] Hugoåšå®¢ä¿å­˜å¤±è´¥ï¼Œä½†æŠ¥å‘Šå·²ä¿å­˜åˆ°å½“å‰ç›®å½•")
    


if __name__ == "__main__":
    main()
